---
title: MongoDB笔记
date: 2020-07-01 19:13:01
permalink: /pages/a16f52/
categories:
  - 其它
  - 存储
---
# MongoDB

[toc]

MongoDB 是一款高性能的 NoSQL（Not Only SQL） 数据库，支持类似 SQL 的功能，性能较高，相比之下不使用 SQL ，没有结构化存储要求（SQL为结构化的查询语句），架构更加灵活。

>四大 NoSQL 数据库： 列存储 Hbase、键值(Key-Value)存储 Redis、图像存储 Neo4j、文档存储MongoDB

MongoDB 介于关系数据库和非关系数据库之间，是功能最丰富、最像关系数据库的非关系数据库。

## MongoDB 系统结构

MongoDB 体系结构如下：

![体系结构](https://gitee.com/leixiaoai/markdown/raw/master/03.其它/01.存储/images/mongodb/体系结构.png)

磁盘文件经过加载之后后形成 MongoDB 实例，一个 MongoDB 实例中可以存放多个数据库（图中的MongoDB 数据库1、MongoDB 数据库2、MongoDB 数据库3），数据库中存放的是一个个 Collection （集合，对应关系型数据库的 table），集合中又存放 Document （文档，对应关系型的记录），Document 中存放 Field（字段，对应关系型数据库列）。

**和关系型数据库对比：**

RDBMS|MongoDB|
-|-|
database（数据库）|database（数据库）|
table （表）|collection（ 集合）|
row（ 行）|document（ BSON 文档）|
column （列）|field （字段）|
index（唯一索引、主键索引）|index （支持地理位置索引、全文索引 、哈希索引）|
join （主外键关联）|embedded Document （嵌套文档）|
primary key(指定1至N个列做主键）| primary key (指定_id field做为主键）|

**BSON：**

BSON（Binary JSON）是一种二进制存储 JSON 的格式，支持内嵌文档对象和数组对象，BSON 有 JSON 没有的一些数据类型，如 Date 和 Binary Data 类型。BSON 是一种 schema-less（格式自由）的存储形式，可以用作网络数据交换，它的优点是灵活性高，它的缺点是空间利用率低。例如：```{key:value，key2:value2}``` ，其中 key 是字符串类型，后面的 value 值。BSON 有三个特点：轻量性、可遍历性、高效性。

**BSON 在 MongoDB 中的使用：**
MongoDB 把 BSON 转化成文档这个概念(Document)，一个 Document 也可以理解成关系数据库中的一条记录(Record)，只是 Document 的变化更丰富一些，比如可以嵌套。MongoDB 中 Document 中可以常用的数据类型：

![document类型](https://gitee.com/leixiaoai/markdown/raw/master/03.其它/01.存储/images/mongodb/document类型.png)

**docker 安装 mongo：**

执行以下命令：

```shell
  # 镜像下载
  docker pull mongo
  # 启动容器
  docker run --name=mongo -v /docker/mongo/data:/data/db -v /docker/mongo/backup:/data/backup -v /docker/mongo/conf:/data/configdb -p 27017:27017 -d mongo:latest --auth

  # 添加用户设置密码
  docker exec -it mongo mongo admin
  db.createUser({user:"admin",pwd:"123456",roles:["root"]});
  db.auth('admin','123456');

  # 连接操作
   mongo --host=localhost --port=27017 -u "admin" -p "123456"
```

## MongoDB 常用命令

参考：<https://www.mongodb.org.cn/manual>

**数据库操作：**

```shell
  # 查看数据库
  show dbs;
  # 切换数据库（如果没有对应的数据库则创建）
  use 数据库名;
  # 创建集合
  db.createCollection(集合名)
  # 查看集合
  show tables;
  show collections;
  # 删除集合
  db.集合名.drop();
  # 删除当前数据库
  db.dropDatabase();
```

**数据添加：**

```shell
  # 插入单条数据
  db.集合名.insert(文档)
  # 例如：（如果没有 test ，会自动创建）
  db.test.insert({name:"张三丰",birthday:new ISODate("1930-07-01"),gender:0,city:"HZ"});
  # 插入多条数据
  db.集合名.insert([文档,文档])
```

插入数据时 _id 没有指定，系统会自动生成（可以指定），默认_id 类型是 ObjectId 类型是一个12字节 BSON 类型数据，由以下格式组成：

- 前 4 个字节表示时间戳 ObjectId("对象Id字符串").getTimestamp() 来获取；
- 接下来的 3 个字节是机器标识码；
- 紧接的两个字节由进程 id 组成（PID）；
- 最后三个字节是随机数;

**数据查询:**

```shell
  # 查询语句，没有条件或者空对象查询所有，sort 1 正序 -1 倒序，pretty 格式化
  db.集合名.find({条件}).sort({key:1}).pretty();
```

比较条件查询：

操作|条件格式|例子|RDBMS中的条件|
-|-|-|-|
等于| {key:value}|db.collection.find({字段名:值}).pretty()| where 字段名=值|
大于| {key:{\$gt:value}}|db.collection.find({字段名:{\$gt:值}}).pretty()|where 字段名>值|
小于| {key:{\$lt:value}}|db.collection.find({字段名:{\$lt:值}}).pretty()|where 字段名<值|
大于等于|{key:{\$gte:value}}|db.collection.find({字段名:{\$gte:值}}).pretty()|where 字段名>=值|
小于等于| {key:{\$lte:value}} |db.collection.find({字段名:{\$lte:值}}).pretty()|where 字段名<=值|
不等于| {key:{\$ne:value}}| db.collection.find({字段名:{\$ne:值}}).pretty()|where 字段名!=值|

逻辑条件：

名称|例子|
-|-
and |db.集合名.find({key1:value1, key2:value2}).pretty()|
or |db.集合名.find({\$or:[{key1:value1}, {key2:value2}]}).pretty()|
not |db.集合名.find({key:{\$not:{\$eq:value}}).pretty()|

分页查询：

```shell
  db.集合名.find({条件}).sort({排序字段:排序方式})).skip(跳过的行数).limit(一页显示多少数据)
```

**数据更新：**

```shell
  # $set ：设置字段值
  # $unset :删除指定字段
  # $inc：在值得基础上加一个数
  db.集合名.update(
    <query>, # 更新条件
    <update>, # 上述操作
    {
      upsert: <boolean>, # 默认 false， true 表示 upsert
      multi: <boolean>, # 默认 false，true 更新满足条件的所有
      writeConcern: <document> # 指定 mongo 对写操作的回执行
    }
  )
  # 例如
  db.c_user.update({name:"张三"},{$set:{age:12}},{multi:true})
```

**数据删除：**

```shell
db.collection.remove(
  <query>,
  {
    justOne: <boolean>,
    writeConcern: <document>
  }
)
# 参数说明：
#  query（可选） :删除的文档的条件。
#  justOne（可选，用默认为 false）:
#      如果设为 true 或 1，则只删除一个文档
#      如果不设置该参数，则删除所有匹配条件的文档。
#  writeConcern（可选）:用来指定 mongod 对写操作的回执行为
```

**聚合操作：**

聚合是 MongoDB 高级查询语言，它允许我们通过转化、合并多个文档的数据，来生成新的信息，例如：求最大值、最小值、平均值。也可以进行复杂数据统计、数据挖掘。聚合操作分为：单目的聚合操作(Single Purpose Aggregation Operation)、聚合管道(Aggregation Pipeline)、MapReduce 编程模型。

- 单目聚合常用的有：count() 和 distinct()

  ```shell
    db.c_user.find().count();
    db.c_user.distinct("name");
  ```

- 聚合管道：

  语法：``` db.collection.aggregate(AGGREGATE_OPERATION) ```

  ```shell
    #  例如: 统计 c_user 中各个 name 出现的次数
    db.c_user.aggregate([{$group:{_id:"$name",count:{$sum:1}}}])
    # 每个名字的平均年龄
    db.c_user.aggregate([{$group:{_id:"$name",avg:{$avg:"$age"}}}])
    # 获取每个 name 对应的年龄，返回值 {name:"张三",age_array:[12,34,53,47]}
    db.c_user.aggregate([{$group:{_id:"$name",age_array:{$push:"$age"}}}])
  ```
  
  常用聚合操作：

  表达式|描述|
  -|-|
  $sum|计算总和|
  $avg|求平均值|
  $min|获取对应值的最小值|
  $max|获取对应值的最大值|
  $first|获取第一个文档数据|
  $last|获取最后一个文档数据|
  $push|把得到的数据插入到数组中|
  $addToSet|把得到的数据插入到 set 中|

  MongoDB 中使用 ``` db.collection.aggregate([{},...]) ``` 方法来构建、使用聚合管道，每个文档在管道中经过一系列处理，输出相应结果。

  常用操作：

  操作|作用|
  -|-|
  $group|将集合中的文档分组，可用于统计结果|
  $project|修改输入文档的结构，用来重命名、增加或删除域、创建计算结果、嵌套文档|
  $match|用于过滤数据，只输出符合条件的文档|
  $limit|用来限制 MongoDB 返回的文档数|
  $skip|在跳过指定数量的文档，返回余下文档|
  $sort|将输入文档排序后输出|
  $geoNear|输出接近某一地理位置的有序文档|

  ```shell
    # 统计每个 name 的平均年龄，重新命名 avg ，输出 {name:"张三",age:12}，而不是 {name:"张三",avg:12}
    db.c_user.aggregate([
      {$group : {_id: "$name", avg:{$avg:"$age"}}},
      {$project : {name: "$name", age : "$avg"}}
    ])
    # 统计每个 name 出现次数，过滤小于等于 12 次的
    db.c_user.aggregate([
      {$group:{_id: "$name",count:{$sum : 1}}},
      {$match:{count:{$gt:12}}}
    ])
  ```

- MapReduce 编程模型

  MapReduce 和 Pipeline 都能用于文档聚合， Pipeline 查询速度快于 MapReduce，MapReduce 能够在多台 Server 上并行执行复杂的聚合逻辑。MongoDB 不允许 Pipeline 的单个聚合操作占用过多的系统内存，如果一个聚合操作消耗 20% 以上的内存，MongoDB 就会停止操作，并向客户端输出错误消息。MapReduce 是一种计算模型，它将大批量的工作（数据）分解（MAP）执行，然后再将结果合并成最终结果（REDUCE）。

  ```shell
  # 语法
  db.collection.mapReduce(
    function() {emit(key,value)}, # map 函数
    function(key,value) {return reduceFunction}, # reduce 函数
    {
      out: collection,
      query: document,
      sort: document,
      limit: number,
      finalize: <function>,
      verbose: <boolean>
    }
  )
  ```

  参数说明：

  map：JavaScript 函数，将输入文档转换为 reduce 需要的文档；
  reduce：JavaScript 函数，合并 map 操作的输出结果；
  out：存放统计结果；
  query： 筛选条件，满足条件的文档才会调用 map 函数；
  sort： 对满足筛选条件的数据排序；
  limit： 发往 map 函数的文档数量的上限；
  finalize：可以对 reduce 输出结果做最后修改；
  verbose：是否显示时间相关信息，默认为 fasle；

  例如：

  ```shell
    # 按照 name 分组，求 age 平均值。输出：{"张三":31,"李四":22}
    db.c_user.mapReduce(
      function() {emit(this.name,this.age);}, # 获取每个文档的 name 、age
      function(key, value) {return Array.avg(value);}, # 对 age 求平均
      {
        query:{age:{$gt: 12}},
        out:"avg_age" # 输出集合名，统计结果存放在 avg_age 中
      }
    )
  ```

## MongoDB 索引

> 索引是对数据库一列或多列值进行排序的存储结构，底层一般是一种树状结构，没有索引查询会进行全表扫描，数据量大的时候会严重降低效率。MongoDB 索引和关系型数据库相同，默认情况下 MongoDB 在一个集合创建时就对 _id 创建了唯一索引。

**索引类型：**

参见官方文档

- 单键索引 (Single Field)：支持所有类型的单个字段索引，并且可以在文档的任何字段上定义，
  对于单个字段索引，索引键的排序顺序无关紧要，因为 MongoDB 可以在任一方向读取索引。
  单个例上创建索引：

  ```shell
    db.集合名.createIndex({"字段名":排序方式}) # 1升序。-1降序
    db.集合名.getIndexes()
  ```

  特殊的单键索引：过期索引 TTL （ Time To Live），TTL 索引是 MongoDB 中一种特殊的索引， 可以支持文档在一定时间之后自动过期删除，目前 TTL 索引只能在单字段上建立，并且字段类型必须是日期类型。

  ```shell
    # expireAfterSeconds：过期时间
    db.集合名.createIndex({"日期字段":排序方式}, {expireAfterSeconds: 秒数})
  ```

- 复合索引(Compound Index）：复合索引支持基于多个字段的索引；
  制作复合索引时要注意的重要事项包括：字段顺序与索引方向。

  参考：<https://blog.csdn.net/leshami/article/details/53542371>

  ```shell
    db.集合名.createIndex( { "字段名1" : 排序方式, "字段名2" : 排序方式 } )
    # 字段顺序
    db.集合名.find({"字段名1":'xx'}) # 启用复合索引
    db.集合名.find({"字段名1" : 'x', "字段名2" : 'x'}) # 启用复合索引
    db.集合名.find({"字段名2":'xx'}) # 不启用复合索引
    # 查询字段排序 {name:1,age:1}
    db.集合名.find().sort({name:1,age:1})# 使用
    db.集合名.find().sort({name:-1,age:-1})# 使用
    db.集合名.find().sort({name:1,age:-1}) # 未使用
    db.集合名.find().sort({name:-1,age:1}) # 未使用
    db.集合名.find().sort({age:1,name:1}) # 未使用
    db.集合名.find().sort({age:-1,name:1}) # 未使用
  ```

- 多键索引（Multikey indexes）：针对数组，MongoDB 支持针对数组中每一个element 创建索引，包括 strings、numbers、nested documents；

- 地理空间索引（Geospatial Index）：针对地理空间坐标数据创建索引；
  2dsphere 索引，用于存储和查找球面上的点；
  2d 索引，用于存储和查找平面上的点；

  ```shell
    db.test.insert({
      loc : { type: "Point", coordinates: [ 120, 40 ] },
      name: "AAA",
      category : "Parks"
    })
    db.test.ensureIndex( { loc : "2dsphere" } )
    # 参数不是1或-1，为2dsphere 或者 2d。还可以建立组合索引。
    db.test.find({
      "loc" : {
        "$geoWithin" : {
          "$center":[[116.482451,39.914176],0.05] # 中心点，0.05 经纬度
        }
      }
    })
  ```

- 全文索引：string 内容的分词查询，支持任意属性值为 string 或 string 数组，一个集合仅支持最多一个Text Index，另外中文分词不理想，推荐ES；

  ```shell
    db.集合名.createIndex({"字段": "text"})
    db.集合名.find({"$text": {"$search": "张"}})
  ```

- 哈希索引 （Hashed Index）：针对属性的哈希值进行索引查询，当要使用 Hashed index 时，MongoDB 能够自动的计算 hash 值，无需程序计算 hash 值，hash index 仅支持单个字段等于查询，不支持范围查询；

  ```shell
    db.集合名.createIndex({"字段": "hashed"})
  ```

**索引和explain 分析：**

索引管理：

```shell
  # 创建索引并在后台运行，数据量大的时候使用
  db.集合名.createIndex({"字段":排序方式}, {background: true});
  # 获取针对某个集合的索引
  db.集合名.getIndexes()
  # 索引的大小
  db.集合名.totalIndexSize()
  # 索引的重建
  db.集合名.reIndex()
  # 索引的删除，_id 对应的索引是删除不了的
  db.集合名.dropIndex(索引名)
  db.集合名.dropIndexes()
```

explain 分析：使用 js 循环插入100万条数据。首先不使用索引字段，查询查看执行计划 ；然后给某个字段建立索引，使用索引字段作为查询条件，再查看执行计划进行分析；
参考：<https://www.cnblogs.com/LO-ME/p/10872953.html>

```shell
  db.集合名.find().sort({name:1,age:1}).explain("allPlansExecution")
```

explain()通过设置不同参数我们可以查看更详细的查询计划；

- queryPlanner：queryPlanner 是默认参数，具体执行计划信息参考下面的表格；
- executionStats：executionStats 会返回执行计划的一些统计信息(有些版本中和allPlansExecution等同)；
- allPlansExecution：allPlansExecution用来获取所有执行计划，queryPlanner 和executionStats的拼接；

![explain](https://gitee.com/leixiaoai/markdown/raw/master/03.其它/01.存储/images/mongodb/explain.png)

queryPlanner：

参数|含义|
-|-|
plannerVersion|查询计划版本，一般1.0|
namespace|要查询的集合，也就是：``数据库.集合``|
indexFilterSet|索引过滤器，针对该query是否有indexFilter|
parsedQuery|查询条件|
winningPlan|执行计划有很多，表示被选中的执行计划|
winningPlan.stage|被选中执行计划的 stage(查询方式)，常见的有：COLLSCAN/全表扫描（“集合扫描”，和 mysql 中 table scan/heap scan 类似，这个就是性能最烂最无奈的由来）、IXSCAN/索引扫描（是IndexScan，这就说明我们已经命中索引了）、FETCH/根据索引去检索文档、SHARD_MERGE/合并分片结果、IDHACK/针对_id进行查询等|
winningPlan.inputStage|用来描述子stage，并且为其父stage提供文档和索引关键字|
winningPlan.stage的child stage|如果此处是IXSCAN，表示进行的是index scanning|
winningPlan.keyPattern|所扫描的index内容|
winningPlan.indexName|winning plan所选用的index|
winningPlan.isMultiKey|是否是Multikey，此处返回是false，如果索引建立在array上，此处将是true|
winningPlan.direction|query查询顺序，此处是forward，如果用了.sort({字段:-1})将显示backward|
winningPlan.indexBounds|winningplan所扫描的索引范围，如果没有制定范围就是[MaxKey,MinKey]，这主要是直接定位到mongodb的chunck中去查找数据，加快数据读取|
winningPlan.filter|过滤条件|
rejectedPlans|被拒绝的执行计划的详细返回，其中具体信息与winningPlan的返回中意义相同|
serverInfo|MongoDB服务器信息|

executionStats：

参数|含义|
-|-|
executionSuccess|是否执行成功|
nReturned|返回的文档数|
executionTimeMillis|执行耗时|
totalKeysExamined|索引扫描次数|
totalDocsExamined|文档扫描次数|
executionStages|这个分类下描述执行的状态|
stage|扫描方式，具体可选值与上文的相同|
executionStages nReturned|查询结果数量|
executionTimeMillisEstimate|检索document获得数据的时间|
inputStage.executionTimeMillisEstimate|该查询扫描文档 index所用时间|
works|工作单元数，一个查询会分解成小的工作单元，works表示单元数|
advanced|优先返回的结果数|
docsExamined|文档检查数目，与totalDocsExamined一致。检查了总共的 document 个数，而从返回上面的nReturned数量|

executionStats返回逐层分析：

- 第一层，executionTimeMillis 最为直观 explain 返回值是 executionTimeMillis 值，指的是这条语句的执行时间，这个值当然是希望越少越好。其中有3个 executionTimeMillis，分别是：
  - executionStats.executionTimeMillis 该 query 的整体查询时间；
  - executionStats.executionStages.executionTimeMillisEstimate 该查询检索document获得数据的时间；
  - executionStats.executionStages.inputStage.executionTimeMillisEstimate 该查询扫描文档 index所用时间；

- 第二层，index与document扫描数与查询返回条目数 这个主要讨论3个返回项 nReturned、totalKeysExamined、totalDocsExamined，分别代表该条查询返回的条目、索引扫描条目、文档扫描条目。 这些都是直观地影响到executionTimeMillis，我们需要扫描的越少速度越快。 对于一个查询，我们最理想的状态是：nReturned=totalKeysExamined=totalDocsExamined

- 第三层，stage 状态分析 那么又是什么影响到了 totalKeysExamined 和 totalDocsExamined ？是 stage 的类型。类型列举如下：
  COLLSCAN：全表扫描
  IXSCAN：索引扫描
  FETCH：根据索引去检索指定document
  SHARD_MERGE：将各个分片返回数据进行merge
  SORT：表明在内存中进行了排序
  LIMIT：使用limit限制返回数
  SKIP：使用skip进行跳过
  IDHACK：针对_id进行查询
  SHARDING_FILTER：通过mongos对分片数据进行查询
  COUNT：利用db.coll.explain().count()之类进行count运算
  TEXT：使用全文索引进行查询时候的stage返回
  PROJECTION：限定返回字段时候stage的返回

  对于普通查询，我希望看到stage的组合(查询的时候尽可能用上索引)：
  Fetch+IDHACKFetch+IXSCAN
  Limit+（Fetch+IXSCAN）
  PROJECTION+IXSCAN
  SHARDING_FITER+IXSCAN

  不希望看到包含如下的stage：
  COLLSCAN(全表扫描)
  SORT(使用sort但是无index)
  COUNT 不使用index进行count)

**慢查询分析：**

慢查询解决步骤：

- 1.开启内置的查询分析器,记录读写操作效率

  ```shell
    db.setProfilingLevel(n,m) # n的取值可选0,1,2（一般设置为1）
    # 0表示不记录
    # 1表示记录慢速操作,如果值为1,m不能为空，单位为ms,用于定义慢速查询的阈值
    # 2表示记录所有的读写操作
    db.setProfilingLevel(1,500)
  ```

- 2.查询监控结果：

  ```shell
    # 导出最慢的三个
    db.system.profile.find().sort({millis:-1}).limit(3)
  ```

- 3.explain 分析

- 4.分析慢速查询：应用程序设计不合理、数据模型设计有误、硬件配置问题、缺少索引等；

- 5.解读 explain 结果，确定是否缺少索引；

**索引原理：**

MongoDB 是文档型的数据库，它使用 BSON 保存数据，比关系型数据库存储更方便。比如：之前关系型数据库中处理用户、订单等数据要建立对应的表，还要建立它们之间的关联关系。但是 BSON 就不一样了，我们可以把一条数据和这条数据对应的其它数据都存入一个 BSON 对象中,这种形式更简单，通俗易
懂。MySql 是关系型数据库，数据的关联性是非常强的，区间访问是常见的一种情况，底层索引组织数据使用 B+ 树，B+ 树由于数据全部存储在叶子节点，并且通过指针串在一起，这样就很容易的进行区间遍历甚至全部遍历。MongoDB使用B树，所有节点都有数据，只要找到指定索引就可以进行访问，单次查询从结构上来看要快于MySql。

B 树是一种自平衡的搜索树，B 树的特点:

- 多路、非二叉树
- 每个节点、既保存数据、又保存索引
- 搜索时、相当于二分查找

![索引原理](https://gitee.com/leixiaoai/markdown/raw/master/03.其它/01.存储/images/mongodb/索引原理1.png)

B+ 树是 B 树的变种，B+ 树的特点:

- 多路非二叉；
- 只有叶子节点保存数据；
- 搜索时、也相当于二分查找；
- 增加了相邻节点指针；

![索引原理](https://gitee.com/leixiaoai/markdown/raw/master/03.其它/01.存储/images/mongodb/索引原理2.png)

从上面我们可以看出 MongoDB 和 MySQL 的区别主要有两个，一个是数据的保存位置，一个是相邻节点的指向。这就造成了 MongoDB 和MySql的差别：

- B+ 树相邻接点的指针可以大大增加区间访问性，可使用在范围查询等，而 B 树每个节点 key 和 data 在一起适合随机读写 ，而区间查找效率很差；

- B+ 树更适合外部存储，也就是磁盘存储，如果使用 B 结构的话，每次磁盘预读中的很多数据是用不上的数据，它没能利用好磁盘预读的提供的数据，由于 B+ 树节点内无 data 域，每个节点能存放的索引更多，索引范围更大更精确；

- B 树每个节点即保存数据又保存索引，树的深度小，所以磁盘IO的次数很少，B+树只有叶子节点保存数据，较B树而言深度大磁盘IO多，但是区间访问比较好；

## MongoDB 示例

**MongoDB的适用场景：**

- 网站数据：Mongo 非常适合实时的插入，更新与查询，并具备网站实时数据存储所需的备份、扩容；

- 缓存：由于性能很高，Mongo 也适合作为信息基础设施的缓存层，在系统重启之后，由Mongo搭建的持久化缓存层可以避免数据源过载；

- 大尺寸、低价值的数据存储：使用传统的关系型数据库存储一些大尺寸低价值数据时会比较浪费（比如日志），在此之前，很多时候程序员往往会选择传统的文件进行存储；

- 高伸缩性的场景：Mongo 非常适合由数十或数百台服务器组成的数据库，Mongo 的路线图中已经包含对 MapReduce 以及集群高可用的解决方案；

- 用于对象及JSON 数据的存储：Mongo 的BSON 数据格式非常适合文档化格式的存储及查询；

**具体应用场景：**

- 游戏场景，使用 MongoDB 存储游戏用户信息，用户的装备、积分等直接以内嵌文档的形式存储，经常修改，方便查询、更新；
- 物流场景，使用 MongoDB 存储订单信息，订单状态在运送过程中会不断更新，以 MongoDB 内嵌数组的形式来存储，一次查询就能将订单所有的变更读取出来；
- 社交场景，使用 MongoDB 存储用户信息，以及用户发表的朋友圈信息，通过地理位置索引实现附近的人、地点等功能；
- 物联网场景，使用 MongoDB 存储所有接入的智能设备信息，以及设备汇报的日志信息，并对这些信息进行多维度的分析；
- 直播，使用 MongoDB 存储用户信息、礼物信息（变化大）等；

**如何抉择：**

应用特征|Yes / No|
-|-|
应用不需要事务及复杂join 支持|？|
新应用，需求会变，数据模型无法确定，想快速迭代开发 |？|
应用需要2000-3000以上的读写QPS（更高也可以）| ？|
应用需要TB甚至 PB 级别数据存储| ?|
应用发展迅速，需要能快速水平扩展 |?|
应用要求存储的数据不丢失（相比内存数据库）| ?|
应用需要99.999%高可用 |?|
应用需要大量的地理位置查询、文本查询（配合 ES）| ？|

满足第一条 + 后面的一两条就可以了

**JAVA使用MongoDB：**

```xml
  <dependency>
    <groupId>org.mongodb</groupId>
    <artifactId>mongo-java-driver</artifactId>
    <version>3.10.1</version>
  </dependency>
```

```java
  // Document 就是 BSON
  // 新增
  MongoClient mongoClient = new MongoClient("192.168.28.52", 37017);
  MongoDatabase database = mongoClient.getDatabase("lxt");
  MongoCollection<Document> collection = database.getCollection("lxt_user");
  Document document = Document.parse("{name:'lisi',city:'bj',birth_day:new ISODate('2001-08-01'),age:34}");
  collection.insertOne(document );
  mongoClient.close();

  // 查找
  MongoClient mongoClient = new MongoClient("192.168.22.163", 37017);
  MongoDatabase database = mongoClient.getDatabase("lxt");
  MongoCollection<Document> collection = database.getCollection("lxt_user");
  Document sdoc=new Document();
  //按age倒序
  sdoc.append("age", -1);
  FindIterable<Document> findIterable =
  collection.find(Filters.gt("age",21)).sort(sdoc);
  for (Document document : findIterable) {
    System.out.println(document);
  }
  mongoClient.close();
```

**Spring 访问MongoDB:**

- 第1步：基于maven新建工程 导入依赖的包；
- 第2步:在配置文件中配置 MongoTemplate；
- 第3步:DAO 实现类注入 MongoTemplate 完成增删改查；
- 第4步: 从Spring容器中获取DAO对象 进行测试 (注意:要开启组件扫描)；

```xml
<!-- xsi:schemaLocation= -->
<!-- http://www.springframework.org/schema/data/mongo -->
<!-- http://www.springframework.org/schema/data/mongo/spring-mongo.xsd -->
<?xml version="1.0" encoding="UTF-8"?>
<beans balabala.....>
  <!-- 构建MongoDb工厂对象 -->
  <mongo:db-factory id="mongoDbFactory" client-uri="mongodb://192.168.22.163:37017/lg_resume"></mongo:db-factory>
  <!-- 构建 MongoTemplate 类型的对象 -->
  <bean id="mongoTemplate" class="org.springframework.data.mongodb.core.MongoTemplate">
    <constructor-arg index="0" ref="mongoDbFactory"></constructor-arg>
  </bean>
<!-- 开启组件扫描 -->
<context:component-scan base-package="com.xn"></context:component-scan>
</beans>

```

## MongoDB 架构

**逻辑结构：**

![框架](https://gitee.com/leixiaoai/markdown/raw/master/03.其它/01.存储/images/mongodb/框架.png)

MongoDB 与 MySQL 中的架构相差不多，底层都使用了可插拔的存储引擎以满足用户的不同需要。用户可以根据程序的数据特征选择不同的存储引擎,在最新版本的 MongoDB 中使用了 WiredTiger 作为默认的存储引擎，WiredTiger 提供了不同粒度的并发控制和压缩机制，能够为不同种类的应用提供了最好的性能和存储率；在存储引擎上层的就是 MongoDB 的数据模型和前面提到的查询语言了，由于 MongoDB 对数据的存储与 RDBMS 有较大的差异，所以它创建了一套不同的数据模型和查询语言；

**数据模型：**

描述数据模型：

- 内嵌：内嵌就是把相关联的数据保存在同一个文档结构之中（比如：商品信息、用户信息放在一起）；
- 引用：引用就是通过存储数据引用信息来实现两个不同文档之间的关联（比如：用户和商品在两个文档，程序解析应用访问）；

内嵌：

- 数据对象之间有包含关系 ,一般是数据对象之间有一对多或者一对一的关系；
- 需要经常一起读取的数据；
- 有 map-reduce/aggregation 需求的数据放在一起，这些操作都只能操作单个 collection；

引用：

- 当内嵌数据会导致很多数据的重复，并且读性能的优势又不足于覆盖数据重复的弊端；
- 需要表达比较复杂的多对多关系的时候；
- 大型层次结果数据集嵌套不要太深；

**存储引擎：**

存储引擎是 MongoDB 的核心组件，负责管理数据如何存储在硬盘和内存上。MongoDB 支持的存储引擎有 MMAPv1 ,WiredTiger 和InMemory：

- InMemory 将数据存储在内存中，只将少量的元数据(meta-data)和诊断日志（Diagnostic）存储到硬盘文件中，不需要硬盘读取操作，大幅度降低了数据查询的延迟（Latency），只做缓存时 InMemory 是不错的选择 ；

- 从 mongodb3.2 开始默认的存储引擎是 WiredTiger 相比 MMAPv1 优势特别明显，3.2版本之前的默认存储引擎是 MMAPv1；

- mongodb4.x 版本不再支持 MMAPv1 存储引擎；

一个存储引擎配置文件：

```yml
  storage:
    # journal 开启日志
    journal:
      enabled: true
    dbPath: /data/mongo/
    ## 是否一个库一个文件夹
    directoryPerDB: true
    ## 数据引擎
    engine: wiredTiger
    ## WT引擎配置
    WiredTiger:
      engineConfig:
        ## WT最大使用cache（根据服务器实际情况调节）
        cacheSizeGB: 2
        ## 是否将索引也按数据库名单独存储
        directoryForIndexes: true
        journalCompressor: none #（默认snappy）
        ## 表压缩配置
        collectionConfig:
          blockCompressor: zlib #(默认snappy,还可选none、zlib)
        ## 索引配置
        indexConfig:
          prefixCompression: true

```

**WiredTiger：**

- 相比 MMAPV1 优势：
  1.文档空间分配方式：WiredTiger使用的是BTree存储 MMAPV1 线性存储，预分配 + Padding；
  2.并发级别：WiredTiger 文档级别锁，MMAPV1 引擎使用表级锁（老版本还是数据库级锁）；
  3.数据压缩：snappy (默认) 和 zlib ,相比 MMAPV1(无压缩) 空间节省数倍；
  4.内存使用：WiredTiger 可以指定内存的使用大小，MMAPV1没有上限，可能导致系统故障；
  5.Cache使用：WT 引擎使用了二阶缓存 WiredTiger Cache、File System Cache来保证硬盘上数据一致性，而MMAPv1 只有journal 日志。

- WT 包含的文件和作用：
  ![wt文件](https://gitee.com/leixiaoai/markdown/raw/master/03.其它/01.存储/images/mongodb/wt文件.png)
  WiredTiger.basecfg: 存储基本配置信息，与 ConfigServer 有关系；
  WiredTiger.lock: 定义锁操作；
  journal: 存储 WAL(Write Ahead Log)；

  WiredTiger.turtle: 存储 WiredTiger.wt 的元数据；
  WiredTiger.wt: 存储 table\* 的元数据；
  table*.wt: 存储各张表的数据；

**WT存储引擎实现原理：**

- 写请求（增删改操作）：
  - 图中的 Transaction 就是增删改操作，操作会默认被写入到 Cache 中并持久化到 Journal 日志中的 WAL (Write Ahead Log)；
  - 每 60s 或 Log 文件达到 2G 做一次 checkpoint 并产生快照 snapshots 文件，当然我们也可以通过在写入时传入 ``j: true`` 的参数强制 journal 文件的同步 ， ``writeConcern({ w: <value>, j: <boolean>, wtimeout: <number>})``。
  - 服务器重启，WiredTiger 初始化时，先使用快照恢复数据，然后使用 WAL 恢复；

  ![WT原理](https://gitee.com/leixiaoai/markdown/raw/master/03.其它/01.存储/images/mongodb/WT原理.png)

  Cache 是基于 BTree 的，节点是一个个 page，root page 是根节点，internal page 是中间索引节点，leaf page 真正存储数据，数据以 page 为单位读写。WiredTiger 采用 Copy on write（先复制，读写针对副本，之后同步到磁盘，每次读写都新建 root page） 的方式管理写操作（insert、update、delete），写操作会先缓存在 cache 里，持久化时，写操作不会在原来的leaf page 上进行，而是写入新分配的page，每次 checkpoint 都会产生一个新的 root page；

- checkpoint 流程：
  - 1. 首先对所有的 table 进行一次 checkpoint，每个 table 的 checkpoint 的元数据更新至 WiredTiger.wt；
  - 2. 对 WiredTiger.wt 进行 checkpoint，将该 table checkpoint 的元数据更新至临时文件 WiredTiger.turtle.set；
  - 3. 将 WiredTiger.turtle.set 重命名为 WiredTiger.turtle；
  - 4. 上述过程如果中间失败，WiredTiger 在下次连接初始化时，首先依据最新的快照恢复数据，然后根据 WAL 恢复数据（按照图中从下至上更新文件，如果失败结合快照和 WAL 恢复）；

- Journaling（恢复数据）：用于在数据库宕机时，保证 MongoDB 中数据的持久性，MongoDB 使用了 Write Ahead Logging 向磁盘上的 journal 文件预先进行写入。除了 journal 日志，MongoDB 还使用检查点（checkpoint）来保证数据的一致性，当数据库发生宕机时，我们就需要 checkpoint 和 journal 文件协作完成数据的恢复工作；
  - 1. 先在数据文件中查找最新的检查点标识符，然后根据检查点恢复数据；
  - 2. 检查点恢复的数据不全，后续需要在 journal 文件中查找标识符对应没有 checkpoint 的记录；
  - 3. 重做对应记录之后 journal 中的全部操作；

  ![WT原理2](https://gitee.com/leixiaoai/markdown/raw/master/03.其它/01.存储/images/mongodb/WT原理2.png)

## MongoDB 集群

**主从复制架构原理和缺陷：**

master-slave 架构中 master 节点负责数据的读写，slave 没有写入权限只负责读取数据。

![主从复制](https://gitee.com/leixiaoai/markdown/raw/master/03.其它/01.存储/images/mongodb/主从复制.png)

- 如何实现：
  如何做到主从复制的呢？靠的是日志文件（和 MySQL 的 BinLog 一样），主节点的操作记录放入 oplog（operation log）中，oplog 存储在内置数据库 local 的 oplog.$main 集合中，这个集合的每个文档都代表主节点上执行的一个操作。从节点会定期从主服务器中获取 oplog 记录，然后在本机上执行实现数据一致。MongoDB 对 oplog 采用的是固定集合，也就是说随着操作过多，新的操作会覆盖旧的操作。

- 缺陷：
  主从结构没有自动故障转移功能（主节点崩溃，从节点没法自动切换为主节点，需要人工介入），需要指定master和slave端，不推荐在生产中使用。mongodb4.0 后不再支持主从复制！使用时会报错：[main] Master/slave replication is no longer supported；

**复制集（replica sets）：**

![复制集](https://gitee.com/leixiaoai/markdown/raw/master/03.其它/01.存储/images/mongodb/复制集.png)

复制集是由一组拥有相同数据集的 mongodb 实例组成的集群，它是2台及2台以上的服务器组成，成员包括 Primary 主节点，secondary 从节点和投票节点。复制集是对主从复制的改进，secondary 也通过 oplog 复制 Primary，改进后没有固定的 primary 节点（primary可以改变，切换自动，无需指定）。复制集提供了数据的冗余备份（保证数据安全），在多个服务器上存储数据副本，提高了数据的可用性,保证数据的安全性。

- 为什么要使用复制集？
  - 1. 高可用：防止设备（服务器、网络）故障、提供自动 failover 功能（失败处理）、保证高可用；
  - 2. 灾难恢复：当发生故障时，可以从其他节点恢复，用于备份；
  - 3. 功能隔离：主节点可以读写，从节点只能读，可以把读的压力分担到从节点（数据分析、挖掘、报表生成、系统任务），减小主节点压力；

**复制集原理：**

- 复制集架构原理：一个复制集中 Primary 节点上能够完成读写操作，Secondary 节点仅能用于读操作。Primary 节点需要记录所有改变数据库状态的操作，这些记录保存在 oplog 中，这个文件存储在 local 数据库，各个 Secondary 节点通过此 oplog 来复制数据并应用于本地，保持本地的数据与主节点的一致。oplog 具有幂等性，即无论执行几次其结果一致,这个比 mysql 的二进制日志更好用；

  ```javascript
  // oplog的组成结构
  {
    "ts" : Timestamp(1446011584, 2),
    "h" : NumberLong("1687359108795812092"),
    "v" : 2,
    "op" : "i",
    "ns" : "test.nosql",
    "o" : { "_id": ObjectId("563062c0b085733f34ab4129"), "name": "mongodb","score": "10"}
  }
  // ts：操作时间，当前 timestamp + 计数器，计数器每秒都被重置
  // h：操作的全局唯一标识
  // v：oplog版本信息
  // op：操作类型
  //    i：插入操作
  //    u：更新操作
  //    d：删除操作
  //    c：执行命令（如 createDatabase，dropDatabase ）
  //    n：空操作，特殊用途
  // ns：数据库+集合名称
  // o：操作内容
  // o2：更新查询条件,仅update操作包含该字段
  ```

  复制集数据同步分为初始化同步（全量复制）和 keep 复制同步（增量复制）。初始化同步指全量从主节点同步数据，如果 Primary 节点数据量比较大同步时间会比较长，而keep复制指初始化同步过后，节点之间的实时同步一般是增量同步。

  初始化同步有以下两种情况会触发：
  (1) Secondary 第一次加入；
  (2) Secondary 落后的数据量超过了一个 oplog 的大小（落后数据太多了），这样也会被全量复制；

- 选举（基于大多数）：主从切换基于选举，选举基于心跳检测，每个节点都维持了和其它节点的心跳，节点通过心跳维持状态同步。

  ![primary-secondary](https://gitee.com/leixiaoai/markdown/raw/master/03.其它/01.存储/images/mongodb/primary-secondary.png)

  - 心跳检测：集群需要保持通信才能知道节点状态。mongodb节点会向副本集中的其他节点每 2 秒就会发送一次 pings包，如果其他节点在10秒钟之内没有返回就标识为不能访问。每个节点内部都会维护一个状态映射表，记录当前每个节点是什么角色、日志时间戳等关键信息，如果主节点发现自己无法与大部分节点通讯时，则把自己降级为 secondary 只读节点。

  - 主节点选举触发时机:
    - 第一次初始化一个复制集时，没有主节点，需要选举；
    - Secondary 节点权重比 Primary 节点高时（需要手动设置优先级），发起替换选举；
    - Secondary 节点发现集群中没有 Primary 时，发起选举，Primary 节点不能访问到大部分成员时主动降级；
  
  - 选举过程（两阶段、多数派协议）：
    - 第一阶段：检测自身是否有被选举的资格（有没有主节点？优先级是不是很低？数据落后很多？是否是裁判节点？），如果有资格，则向其它节点发起本节点选举资格的 FreshnessCheck，进行同僚仲裁（其它节点检查它的选举资格），如果同僚仲裁通过，进入第二阶段；

    - 第二阶段：发起者向集群中存活节点发送 Elect(选举)请求，仲裁者收到请求后执行一系列合法性检查，如果检查通过，则仲裁者(一个复制集中最多 50 个节点，其中只有7个具有投票权)给发起者投一票。有一系列协议防止重复投票：第一个版本 pv0 通过 30 秒选举锁（30秒只投一次票）防止一次选举中两次投票。第二个版本 pv1 使用了 terms(一个单调递增的选举计数器)来防止在一次选举中投两次票的情况。

    - 第三节点：多数派协议计票，发起者如果获得超过半数的投票，则选举通过，自身成为 Primary 节点。如果只有一个肯定能满足大多数，如果有多个同优先级的节点同时通过第一阶段的同僚仲裁并进入第二阶段，会造成当选票不足，此时 sleep[0,1] 秒内的随机时间，再次尝试选举。获得低于半数选票的原因，还可能是网络原因；

**复制集搭建：**

![复制集搭建](https://gitee.com/leixiaoai/markdown/raw/master/03.其它/01.存储/images/mongodb/复制集搭建.png)

- 1.主节点配置 mongo_37017.conf：

  ```bash
    # 主节点配置
    # 需要保证 /data/mongo/data/server1、/data/mongo/logs 存在
    dbpath=/data/mongo/data/server1
    bind_ip=0.0.0.0
    port=37017
    fork=true
    logpath=/data/mongo/logs/server1.log
    replSet=lxt_cluster
  ```

- 2.从节点1配置 mongo_37018.conf：

  ```bash
    # 从节点配置
    dbpath=/data/mongo/data/server2
    bind_ip=0.0.0.0
    port=37018
    fork=true
    logpath=/data/mongo/logs/server2.log
    replSet=lxt_cluster
  ```

- 3.从节点2配置 mongo_37019.conf：

  ```bash
    # 从节点配置
    dbpath=/data/mongo/data/server3
    bind_ip=0.0.0.0
    port=37019
    fork=true
    logpath=/data/mongo/logs/server3.log
    replSet=lxt_cluster
  ```

- 4.初始化节点配置：

  ```javascript
    // 启动三个节点 然后进入任意一个节点运行如下命令：

    var cfg = {
      // 集群ID
      "_id":"lxt_cluster",
      // 协议
      "protocolVersion" : 1,
      "members":[
        // 10保证 37017 成为主节点，priority 0~1000
        {"_id":1,"host":"192.168.22.163:37017","priority":10},
        {"_id":2,"host":"192.168.22.163:37018"}
        // 37019 用于第5步的演示，所以没加
      ]
    }
    rs.initiate(cfg)
    // 查看集群状态
    rs.status()
  ```

- 5.节点的动态增删：

  ```javascript
    // 增加节点
    rs.add("192.168.22.163:37019")
    // 删除slave 节点
    rs.remove("192.168.22.163:37019")
  ```

- 6.复制集操作演示：
  - 进入主节点 -----> 插入数据 ------> 进入从节点验证；
  ***注意:默认节点下从节点不能读取数据。调用 rs.slaveOk() 解决***
  - 为了保证高可用，在集群当中如果主节点挂掉后，会自动在从节点中选举一个重新做为主节点。rs.status()
  - 节点说明：
    PRIMARY 节点： 可以查询和新增数据；
    SECONDARY 节点：只能查询不能新增 基于 priority 权重可以被选为主节点；
    ARBITER 节点： 不能查询数据和新增数据，不能变成主节点；

**复制集成员(members)的配置参数：**

参数字段|类型说明|格式|说明|
-|-|-|-|
_id|整数|_id:0|复制集中唯一标识|
host|字符串|host:"主机:端口"|节点主机名|
arbiterOnly|布尔值|arbiterOnly:true|是否为仲裁节点（不存数据，不能选自己为主节点）|
priority|整数| priority=0\|1 |默认1，是否有资格变成主节点，取值范围0-1000，0永远不会变成主节点|
hidden|布尔值|hidden=true\|false，0\|1 |隐藏节点（只存数据，不访问，为了安全考虑），权重必须为0，才可以设置|
votes|整数|votes= 0\|1 |是否为投票节点,0 不投票，1投票|
slaveDelay|整数|slaveDelay=3600|从库的延迟多少秒（隔多少秒复制一次）|
buildIndexes|布尔值|buildIndexes=true\|false,0\|1|主库的索引，从库也创建，_id索引无效|

例如：

```javascript
  var cfg ={
    "_id":"lxt_cluster",
    "protocolVersion" : 1,
    "members":[
      {"_id":1,"host":"192.168.22.163:37017","priority":10},
      {"_id":2,"host":"192.168.22.163:37018","priority":0},
      {"_id":3,"host":"192.168.22.163:37019","priority":5},
      {"_id":4,"host":"192.168.22.163:37020","arbiterOnly":true}
    ]
  };
  // 重新装载配置（在主节点），并重新生成集群节点。
  rs.reconfig(cfg)
  //重新查看集群状态
  rs.status()
```

有仲裁节点复制集搭建：和上面的配置步骤、配置相同，主节点执行 ``rs.addArb("192.168.22.163:37020")``

**分片集群 Shard Cluster：**

- 什么是分片：分片（sharding）是 MongoDB 将大型集合水平分割到不同服务器（或者复制集）上所采用的方法，不需要功能强大的计算机就可以存储更多的数据，处理更大的负载。

- 为什么要分片：
  - 1.单机磁盘存储容量超出；
  - 2.活跃的数据集超出单机内存容量，请求都要从磁盘读取数据，影响性能；
  - 3.IOPS（每秒处理的IO）超出单个 MongoDB 节点的服务能力（CPU不够了），随着数据的增长，单机实例的瓶颈会越来越明显；
  - 4.副本集具有节点数量（50个）限制；

  > 垂直扩展：单机增加更多的CPU和存储资源来扩展容量。
    水平扩展：将数据集分布在多个服务器上，水平扩展即分片。

**分片原理：**

![分片原理](https://gitee.com/leixiaoai/markdown/raw/master/03.其它/01.存储/images/mongodb/分片原理.png)

分片集群由以下3个服务组成：

- Shards Server（分片服务器）: 每个 shard 由一个或多个 mongod 进程组成，用于存储数据（每个分片都存放一部分）；
- Router Server: 应用程序不直接访问分片节点，所有请求需要通过路由节点转发，不需要在应用程序添加一个路由选择器，Router 就是一个请求分发中心，它负责把请求按规则转发到对应的 Shard 服务器上；
- Config Server: 路由规则等只能存放在内存，重启后会重置，配置节点用于存储所有数据库元信息（路由、分片）的配置；

其它概念：

- 片键（shard key）：拆分标准，比如：用户年龄 <20 拆分到分片1，其它拆分到分片2；
- 区块（chunk）：在一个shard server内部，MongoDB还是会把数据分为chunks（比如：第一个区块是年龄小于五岁的），每个chunk代表这个 shard server 内部一部分数据。MongoDB分割分片数据到区块，每一个区块包含基于分片主键的左闭右开的区间范围；

分片策略：

- 范围分片（Range based sharding）：

  ![分片策略](https://gitee.com/leixiaoai/markdown/raw/master/03.其它/01.存储/images/mongodb/分片策略.png)
  范围分片是基于分片主键的值切分数据，每一个区块将会分配到一个范围（比如：图中可以把[0,20)分到第一个片、[20,40)分到第二个...）；
  优点：区间查询效率高，例如查找X的值在[20,30)之间的数据，mongo 路由根据Config server中存储的元数据，可以直接定位到指定的shard的Chunk中；
  缺点: 如果shard key有明显递增（或者递减）趋势，则新插入的文档会分布到同一个chunk（比如：id 从是递增的，新增加的都会进入一个chunk），服务器的写能力被限制在一块；

- hash 分片（Hash based sharding）：

  ![hash分片](https://gitee.com/leixiaoai/markdown/raw/master/03.其它/01.存储/images/mongodb/hash分片.png)
  Hash 分片是计算一个分片主键的hash值，每一个区块将分配一个范围的hash值，能够确保相邻的数据被分配到不同的shard，Hash分片与范围分片互补；
  优点：能将文档随机的分散到各个chunk，充分的扩展写能力，弥补了范围分片的不足；
  缺点：不能高效地进行范围查询，所有的范围查询要分发到后端所有的Shard，才能找出满足条件的文档；

- 组合片键：hash 片和范围分片各自有自己的缺点，能不能中和一下优点？我们可以在shard中使用范围，chunk 中使用 hash 思想（不能直接用，因为范围索引和hash不能叠加），我们可以使用两个字段，前面一个控制 shard，后面一个控制 chunk。

合理的选择 shard key： 从两个方面考虑，数据的查询和写入，最好的效果就是数据查询时能命中更少的分片，数据写入时能够随机的写入每个分片，关键在于如何权衡性能和负载。

**具体步骤：**

两个分片集群，路由节点，配置集群

- 1. 配置节点集群

  - 节点配置：

    ```shell
      # 数据库文件位置
      dbpath=config/config1
      #日志文件位置
      logpath=config/logs/config1.log
      # 以追加方式写入日志
      logappend=true
      # 是否以守护进程方式运行
      fork = true
      bind_ip=0.0.0.0
      port = 17017
      # 表示是一个配置服务器
      configsvr=true
      #配置服务器副本集名称
      replSet=configsvr
  
      # 数据库文件位置
      dbpath=config/config2
      #日志文件位置
      logpath=config/logs/config2.log
      # 以追加方式写入日志
      logappend=true
      # 是否以守护进程方式运行
      fork = true
      bind_ip=0.0.0.0
      port = 17018
      # 表示是一个配置服务器
      configsvr=true
      #配置服务器副本集名称
      replSet=configsvr

      # 数据库文件位置
      dbpath=config/config3
      #日志文件位置
      logpath=config/logs/config3.log
      # 以追加方式写入日志
      logappend=true
      # 是否以守护进程方式运行
      fork = true
      bind_ip=0.0.0.0
      port = 17019
      # 表示是一个配置服务器
      configsvr=true
      #配置服务器副本集名称
      replSet=configsvr
    ```

  - 启动配置节点：

    ```shell
      ./bin/mongod -f config/config-17017.conf
      ./bin/mongod -f config/config-17018.conf
      ./bin/mongod -f config/config-17019.conf
    ```

  - 进入任意节点的mongo shell 并添加配置节点集群

    ```javascript
      ./bin/mongo --port 17017;
      // 注意一定要 use admin
      use admin;
      var cfg = {
        "_id":"configsvr",
        "members":[
          {"_id":1,"host":"192.168.22.163:17017"},
          {"_id":2,"host":"192.168.22.163:17018"},
          {"_id":3,"host":"192.168.22.163:17019"}
        ]
      };
      rs.initiate(cfg)
    ```

- 2.shard1 集群

  - shard1集群搭建37017到37019

    ```shell
      dbpath=shard/shard1/shard1-37017
      bind_ip=0.0.0.0
      port=37017
      fork=true
      logpath=shard/shard1/shard1-37017.log
      replSet=shard1
      shardsvr=true

      dbpath=shard/shard1/shard1-37018
      bind_ip=0.0.0.0
      port=37018
      fork=true
      logpath=shard/shard1/logs/shard1-37018.log
      replSet=shard1
      shardsvr=true

      dbpath=shard/shard1/shard1-37019
      bind_ip=0.0.0.0
      port=37019
      fork=true
      logpath=shard/shard1/logs/shard1-37019.log
      replSet=shard1
      shardsvr=true
    ```

  - 启动每个mongod 然后进入其中一个进行集群配置

    ```javascript
      var cfg = {
        "_id":"shard1",
        "protocolVersion" : 1,
        "members":[
          {"_id":1,"host":"192.168.22.163:37017"},
          {"_id":2,"host":"192.168.22.163:37018"},
          {"_id":3,"host":"192.168.22.163:37019"}
        ]
      };
      rs.initiate(cfg)
      rs.status()
    ```

- 3.shard2 集群搭建47017到47019

  - 配置：

    ```shell
      dbpath=shard/shard2/shard2-47017
      bind_ip=0.0.0.0
      port=47017
      fork=true
      logpath=shard/shard2/logs/shard2-47017.log
      replSet=shard2
      shardsvr=true

      dbpath=shard/shard2/shard2-47018
      bind_ip=0.0.0.0
      port=47018
      fork=true
      logpath=shard/shard2/logs/shard2-47018.log
      replSet=shard2
      shardsvr=true

      dbpath=shard/shard2/shard2-47019
      bind_ip=0.0.0.0
      port=47019
      fork=true
      logpath=shard/shard2/logs/shard2-47019.log
      replSet=shard2
      shardsvr=true
    ```

  - 启动每个mongod 然后进入其中一个进行集群配置

      ```javascript
        var cfg = {
          "_id":"shard2",
          "protocolVersion" : 1,
          "members":[
            {"_id":1,"host":"192.168.22.163:47017"},
            {"_id":2,"host":"192.168.22.163:47018"},
            {"_id":3,"host":"192.168.22.163:47019"}
          ]
        };
        rs.initiate(cfg)
        rs.status()
      ```

- 4.配置和启动路由节点（route-27017.conf）

  ```shell
    port=27017
    bind_ip=0.0.0.0
    fork=true
    logpath=route/logs/route.log
    # 指定配置服务器
    configdb=configsvr/192.168.22.163:17017,192.168.22.163:17018,192.168.22.163:17019

    # 启动路由节点使用 mongos （注意不是mongod）
    ./bin/mongos -f route/route-27017.conf
  ```

- 5.mongos（路由）中添加分片节点

  ```shell
    # 进入路由
    mongo --port 27017
    sh.status();
    # 名称/ip:port,ip:port
    sh.addShard("shard1/192.168.22.163:37017,192.168.22.163:37018,192.168.22.163:37019");
    sh.addShard("shard2/192.168.22.163:47017,192.168.22.163:47018,192.168.22.163:47019");
    sh.status();
  ```

- 6.开启数据库和集合分片(指定片键)：

  ```shell
    # 继续使用mongos完成分片开启和分片大小设置
    # 为数据库（可以不存在）开启分片功能
    sh.enableSharding("xm")
    # 为指定集合开启分片功能
    sh.shardCollection("xm.test",{"name(片键字段名)":"hashed(索引说明)"})
  ```

- 7.向集合中插入数据测试

  ```javascript
    // 通过路由循环向集合中添加数
    use xm;
    for(var i=1;i<= 1000;i++){
      db.test.insert({"name":"test"+i,salary:(Math.random()*20000).toFixed(2)});
    }
  ```

- 8.验证分片效果：分别进入 shard1 和 shard2 中的节点，执行 find 进行验证；

## MongoDB 安全认证

MongoDB 默认是没有账号的，可以直接连接，无须身份验证。从2016年开始，发生过多起MongoDB黑客赎金事件，大部分MongoDB安全问题暴露出
了安全问题的短板其实是用户，首先用户对于数据库的安全不重视，其次用户在使用过程中可能没有养成定期备份的好习惯，最后是企业可能缺乏有经验和技术的专业人员。

- 安全认证首先要创建用户：

```javascript
  use admin;
  // db.createUser(userDocument)：用于创建 MongoDB 登录用户以及分配权限的方法
  db.createUser({
    user: "账号", //创建的用户名称，如 admin、root 、lxt
    pwd: "密码", // 用户登录的密码
    roles: [ // 为用户分配的角色，不同的角色拥有不同的权限，参数是数组，可以同时设置多个
      {
        role: "角色", //角色，MonngoDB 已经约定好的角色
        db: "安全认证的数据库" // 数据库实例名称，包括 MongoDB 4.0.2 默认自带的有 admin、local、config、test 等
      },
      { role: "角色", db: "安全认证的数据库" }
    ]
  })
  // 例如：
  db.createUser({
    user:"root",
    pwd:"123321",
    roles:[{role:"root",db:"admin"}]
  })
```

- 其它操作：

```javascript
  // 修改密码
  db.changeUserPassword( 'root' , 'rootNew' );
  // 用户添加角色
  db.grantRolesToUser( '用户名' , [{ role: '角色名' , db: '数据库名'}])
  // 以auth 方向启动mongod
  ./bin/mongod -f conf/mongo.conf --auth // 也可以在mongo.conf 中添加auth=true 参数
  // 验证用户账号密码
  db.auth("root","rootNew") // 返回1，认证通过
  // 删除用户
  db.dropUser("用户名")
```

**角色：**

内置角色：

- read：允许用户读取指定数据库；
- readWrite：允许用户读写指定数据库；
- 管理员相关：
  - dbAdmin：允许用户在指定数据库中执行管理函数，如索引创建、删除，查看统计或访问 system.profile；
  - userAdmin：允许用户向 system.users 集合写入，可以找指定数据库里创建、删除和管理用户；
  - clusterAdmin：只在 admin 数据库中可用，赋予用户所有分片和复制集相关函数的管理权限；
  - readAnyDatabase：只在admin数据库中可用，赋予用户所有数据库的读权限；
  - readWriteAnyDatabase：只在admin数据库中可用，赋予用户所有数据库的读写权限；
  - userAdminAnyDatabase：只在admin数据库中可用，赋予用户所有数据库的userAdmin权限；
  - dbAdminAnyDatabase：只在admin数据库中可用，赋予用户所有数据库的dbAdmin权限；
  - root：只在admin数据库中可用。超级账号，超级权限；
  - dbOwner：库拥有者权限，即readWrite、dbAdmin、userAdmin角色的合体；

各个类型用户对应的角色：

- 数据库用户角色：read、readWrite；
- 数据库管理角色：dbAdmin、dbOwner、userAdmin；
- 集群管理角色：clusterAdmin、clusterManager、clusterMonitor、hostManager；
- 备份恢复角色：backup、restore；
- 所有数据库角色：readAnyDatabase、readWriteAnyDatabase、userAdminAnyDatabase、dbAdminAnyDatabase；
- 超级用户角色：root；
- 这里还有几个角色间接或直接提供了系统超级用户的访问（dbOwner 、userAdmin、userAdminAnyDatabase）；

**单机安全认证：**

案例中：

- 创建 mydb1 数据库；
- 在 mydb1 中创建了两个用户，zhangsan 拥有读写权限，lisi 拥有只读权限；
- 测试这两个账户的权限、以超级管理员登录测试权限；

具体过程：

- 创建管理员：MongoDB 服务端开启安全检查之前，至少需要有一个管理员账号，admin 数据库中的用户都被视为管理员；如果 admin 库没有任何用户的话，即使在其他数据库中创建了用户，启用身份验证，默认的连接方式依然会有超级权限，即仍然可以不验证账号密码照样能进行 CRUD，安全认证相当于无效。

  ```javascript
    ./bin/mongod -f mongo.cnf // 启动
    ./bin/mongod --port=27017
    use admin;
    db.createUser({
      user:"root",
      pwd:"123456",
      roles:[{role:"root",db:"admin"}]
    });
  ```

- 创建普通用户：如下所示 mydb1 是自己新建的数据库，没安全认证之前可以随意 CRUD，其余的都是 mongoDB 4.0.2 自带的数据库；

  ```javascript
    show dbs;
    use mydb1;
    db.c1.insert({name:"testdb1"});
    db.c1.insert({name:"testdb1"});
    show tables;
    db.c1.find();
  ```

  为 mydb1 数据库创建了两个用户，zhangsan 拥有读写权限，lisi 拥有只读权限，密码都是 123456：

  ```javascript
    use mydb1;// 需要切库
    db.createUser({
      user:"zhangsan",
      pwd:"123456",
      roles:[{role:"readWrite",db:"mydb1"}]
    });
    db.createUser({
      user:"lisi",
      pwd:"123456",
      roles:[{role:"read",db:"mydb1"}]
    })
  ```

  从客户端关闭 MongoDB 服务端：

  ```javascript
    use admin;
    db.shutdownServer();
  ```

- MongoDB 安全认证方式启动：

  ```shell
    mongod --dbpath=数据库路径 --port=端口 --auth
    #也可以在配置文件中 加入 auth=true
  ```

- 分别以普通用户登录验证权限：普通用户现在仍然像以前一样进行登录，如下所示直接登录进入 mydb1 数据库中，登录是成功的，只是登录后日志少了很多东西，而且执行 show dbs 命令，以及 show tables 等命令都是失败的，即使没有被安全认证的数据库，用户同样操作不了，这都是因为权限不足，用户只能在自己权限范围内的数据库中进行操作；

  ```javascript
    mongo localhost:57017/mydb1
    show dbs;
  ```

  如下所示，登录之后必须使用 db.auth("账号","密码") 方法进行安全认证，认证通过，才能进行权限范围内的操作：

  ```javascript
    use mydb1; // admin 需要 use admin
    db.auth("zhangsan","123456");
    show dbs;
    show tables;
  ```

- 以管理员登录验证权限：客户端管理员登录如下所示 管理员 root 登录，安全认证通过后，拥有对所有数据库的所有权限；

  ```javascript
    mongo localhost:57017;
    use admin;
    db.auth("root","root");
    show dbs;
  ```

**集群安全认证：**

- 开启安全认证之前，进入路由创建管理员（参考单节点）和普通用户：

  ```javascript
    use lxt;
    db.createUser({
      user:"lxt",
      pwd:"123456",
      roles:[{role:"readWrite",db:"lxt"}]
    })
  ```

- 关闭所有的配置节点、分片节点和路由节点：

  ```shell
    # 节点很多，可以安装 psmisc 批量关闭
    yum install psmisc
    # 安装完之后可以使用killall 命令 快速关闭多个进程
    killall mongod
  ```

- 生成密钥文件，并修改权限（分片、集群使用秘钥文件）：

  ```shell
    openssl rand -base64 756 > data/mongodb/testKeyFile.file
    chmod 600 data/mongodb/keyfile/testKeyFile.file
  ```

- 配置节点集群和分片节点集群，开启安全认证和指定密钥文件（所有节点配置都要修改）：

  ```shell
    auth=true
    keyFile=data/mongodb/testKeyFile.file
  ```

- 在路由配置文件中，设置密钥文件（不需要加 auth）：

  ```shell
    keyFile=data/mongodb/testKeyFile.file
  ```

- 按顺序依次启动配置节点、分片节点、路由节点，使用路由进行权限验证：

  ```shell
    # 配置节点
    ./bin/mongod -f config/config-17017.conf
    ./bin/mongod -f config/config-17018.conf
    ./bin/mongod -f config/config-17019.conf
    # 分片节点
    ./bin/mongod -f shard/shard1/shard1-37017.conf
    ./bin/mongod -f shard/shard1/shard1-37018.conf
    ./bin/mongod -f shard/shard1/shard1-37019.conf
    ./bin/mongod -f shard/shard2/shard2-47017.conf
    ./bin/mongod -f shard/shard2/shard2-47018.conf
    ./bin/mongod -f shard/shard2/shard2-47019.conf
    # 路由节点
    ./bin/mongos -f route/route-27017.conf
  ```

**Spring boot 连接安全认证的分片集群：**

  ```javascript
    spring.data.mongodb.username=账号 // root 用户可能不能操作需要认证的mongodb
    spring.data.mongodb.password=密码
    #spring.data.mongodb.uri=mongodb://账号:密码@IP:端口/数据库名
  ```
